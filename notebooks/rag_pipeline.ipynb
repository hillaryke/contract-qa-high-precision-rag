{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from src import get_answer, load_documents_from_dir, save_to_chroma, get_vectorstore, split_text, get_retriever\n",
    "from src.utils import format_docs_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 09:58:45 - src.chroma_store - INFO - Loading documents from data/content\n",
      "2024-07-03 09:58:53 - src.chroma_store - INFO - Clearing out the chroma database.\n",
      "2024-07-03 09:58:53 - src.chroma_store - INFO - Creating a new chroma database.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 1999 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 09:58:55 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2024-07-03 09:59:01 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-03 09:59:10 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the purpose of the escrow?\"\n",
    "\n",
    "def initialize_vectorstore():\n",
    "    # Load the documents from the data directory.\n",
    "    documents = load_documents_from_dir(\"data/content\")\n",
    "    # Split the documents into chunks.\n",
    "    chunks = split_text(documents)\n",
    "    # Save the chunks to the chroma store.\n",
    "    vectorstore = save_to_chroma(chunks)\n",
    "    return vectorstore\n",
    "vectorstore = initialize_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 0.5\n",
    "similarity_count = 5\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                                      search_kwargs={'score_threshold': similarity_threshold,\n",
    "                                                      \"k\": similarity_count})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \" Whose consent is required for the assignment of the Agreement by the Buyer?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag_pipeline import get_answer, create_rank_fusion_chain, get_unique_union\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "# from src.utils import format_tuple_docs_to_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tuple_docs_to_text(docs):\n",
    "    \"\"\" Formats a list of (doc, score) tuples into a text string. \"\"\"\n",
    "    return \"\\n\\n---\\n\\n\".join(doc.page_content for doc, _ in docs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 10:44:23 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-03 10:44:24 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-03 10:44:24 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-03 10:44:24 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-03 10:44:24 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-03 10:44:24 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-03 10:44:25 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "retrieval_chain = create_rank_fusion_chain(question, llm, retriever)\n",
    "docs = retrieval_chain.invoke({\"question\": question})\n",
    "\n",
    "context_text = format_tuple_docs_to_text(docs)\n",
    "\n",
    "def generate_answer(question, context, llm = None):\n",
    "\n",
    "    # RAG\n",
    "    template = \"\"\"Answer the following question based on this context:\n",
    "    For questions starting with \"Is\", start \"Yes\" or \"No\" then proceed.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    final_rag_chain = (\n",
    "        {\"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = final_rag_chain.invoke({\"context\":context, \"question\":question})\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "answer = generate_answer(question, context_text, retriever=retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The consent of the Sellers is required for the assignment of the Agreement by the Buyer.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
